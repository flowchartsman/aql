{
package parser

	// helper method to exfiltrate pigeon's generated error type
func getParseError(err error) error {
	switch ev := err.(type) {
	case errList:
		if pe, ok := ev[0].(*parserError); ok {
			return &ParseError{
				Inner:    pe.Inner,
				Line:     pe.pos.line,
				Column:   pe.pos.col,
				Offset:   pe.pos.offset,
				Prefix:   pe.prefix,
				Expected: pe.expected,
			}
		}
	}
	return err
}

// ParseQuery parses the AQL query string and returns the query root node
func ParseQuery(query string) (*Node, error) {
	v, err := Parse("", []byte(query))
	if err != nil {
		return nil, getParseError(err)
	}
	return getRootNode(v)
}

// ParseQueryReader parses the AQL query from an io.Reader and returns the query
// root node
func ParseQueryReader(queryReader io.Reader) (*Node, error) {
	v, err := ParseReader("", queryReader)
	if err != nil {
		return nil, getParseError(err)
	}
	return getRootNode(v)
}
}

/******
*******
GRAMMAR
*******
*******/

Start <- Query EOF

Query <- OrClause

/****
NODES
*****/

//TODO: Negatable
OrClause <- lhs:AndClause space logicalOR space rhs:OrClause {
    return &Node {
        NodeType: NodeOr,
        Left: lhs.(*Node),
        Right: rhs.(*Node),
    }, nil
} / AndClause

AndClause <- lhs:Comparison space logicalAND space rhs:AndClause {
    return &Node {
        NodeType: NodeAnd,
        Left: lhs.(*Node),
        Right: rhs.(*Node),
    }, nil
} / Comparison

//TODO: Negatable
Comparison <- '(' space? query:Query space? ')'{
    return query, nil
} /  field:Field ':' operation:opCOMP? space? values:ValueList {
    var opOut string
    if operation == nil {
        opOut = "=="
    } else {
        opOut = operation.(string)
    }
    return &Node{
        NodeType: NodeTerminal,
        Comparison:Comparison{
            Op: opOut,
            Negated: false,  //TODO
            Field: field.([]string),
            Values: values.([]string),
        },
    }, nil
}

/*****
FIELDS
******/

//TODO add array specifier? like foo.bar[*].baz[1]
Field <- first:FieldPiece rest:('.' FieldPiece)* {
    return getTokens(first, rest, 1), nil
}

FieldPiece <- QuotedFieldPiece / UnquotedFieldPiece / Star

UnquotedFieldPiece <- [a-z0-9_]i+ {
    return string(c.text), nil
}

QuotedFieldPiece <- QuotedValue {
    return string(c.text), nil
}

Star <- '*' {
    return "*", nil
}

/*****
VALUES
******/

//ADD PROPER RANGE '[X TO Y]' range here or switch to full lucene
ValueList <- '[' space? first:Value rest:( space? ',' space? Value )* space? ']' {
    return getTokens(first, rest, 3), nil
} / value:Value {
    return []string{value.(string)}, nil
}

Value <- QuotedValue {
    c.text = bytes.Replace(c.text, []byte(`\/`), []byte(`/`), -1)
    return strconv.Unquote(string(c.text))
} / RegexValue {
    c.text = bytes.Replace(c.text, []byte(`\/`), []byte(`/`), -1)
    // TODO: below is handled in jsonquery at the moment, revisit when converting stuff to types
    // return c.text = c.text[1:len(c.text)-1], nil
    return string(c.text), nil
} /
BareValue {
    return string(c.text), nil
}

/*******************
SPECIFIC VALUE TYPES
********************/

QuotedValue ← '"' ( !EscapedChar . / '\\' EscapeSequence )* '"'

EscapedChar ← [\x00-\x1f"\\]

EscapeSequence ← SingleCharEscape / UnicodeEscape

SingleCharEscape ← ["\\/bfnrt]

UnicodeEscape ← 'u' HexDigit HexDigit HexDigit HexDigit

HexDigit ← [0-9a-f]i

ValueChars <- [a-zA-Z0-9 !]

RegexValue <- '/' ( !REscapedChar . / '\\' '/' )* '/'
REscapedChar ← [\x00-\x1f"/\\]

//more here, longest rule first
//TODO: maybe constrain non-numeric barevalues to special ops?
//TODO!!: These should each have their own type that's determined during parsing and then each type tan say whether or not it can do an operation maybe
//TODO: value specifiers like "reltime:(-2 days)"
BareValue  <- Timestamp
            / CIDRValue
            / NumericValue
            / BoolValue

BoolValue <- "false" /"true"

NumericValue <- Float / Integer

Float <- [0-9]+ '.' [0-9]+

Integer <- [0-9]+

CIDRValue <- Octet '.' Octet '.' Octet '.' Octet '/' [0-9][0-9]? {
    // we don't want to do anything heavy in the parser, just assert that
    // barewords more or less conform. Actual parsing will be done when building
    // the query. This can be moved into the parser later
    return string(c.text), nil
}

Octet <- [0-9][0-9]?[0-9]?

/*RFC3339*/
Timestamp <- dateTime / fullDate

/*TODO: DO FUNCS*/
dateTime <- fullDate ("T"i / " ") fullTime
fullDate <- dateFullyear '-' dateMonth '-' dateMday

dateFullyear <- Digit4
dateMonth <- Digit2
dateMday <- Digit2
timeHour <- Digit2
timeMinute <- Digit2
timeSecond <- Digit2
timeSecfrac <- '.' [0-9]+
timeNumoffset <- ('+' / '-') timeHour ':' timeMinute
timeOffset <- "Z"i / timeNumoffset
partialTime <- timeHour ':' timeMinute ':' timeSecond timeSecfrac?
fullTime <- partialTime timeOffset
Digit4 <- [0-9][0-9][0-9][0-9]
Digit2 <- [0-9][0-9]

/****************
LOGICAL OPERATORS
*****************/

logicalOR <- "OR"

logicalAND <- "AND"

/*******************
COMPARISON OPERATORS
********************/

opCOMP <- opCustom
/ "><" {
    return string(c.text), nil
} / [!] {
    return string(c.text), nil
} / [<>] '='? { 
    return string(c.text), nil
}

opCustom <- '=' opname:[a-z]i+ '='{
    return toString(opname)
}

/**********************
WHITESPACE AND TERMINAL
***********************/

space <- [ \n\t\r]+

EOF = !.

/*****************************
TERMINAL ERROR HANDLING STATES
******************************/

/*
ErrOp <- #{
    return fmt.Errorf("invalid operator")
}
*/